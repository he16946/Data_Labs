{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMr1nJBoKgXvuwcWJUpgELe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/he16946/Data_Labs/blob/master/Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6NEtiOIloO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/sagihaider/CE888_2020.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-DMy-7RKxNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/CE888_2020/Lab_8/data.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkkVjkjsLSoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install tensorflow==1.3.0\n",
        "! pip install keras==2.0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI_q13InLaWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from CE888_2020.Lab_8.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNl1c_mNLkaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "7c92b6c2-f0c7-4d2e-f0bf-9fd08b9bdd46"
      },
      "source": [
        "#Load image \n",
        "\n",
        "img_path = '/content/CE888_2020/Lab_8/elephant.jpg' \n",
        "img = image.load_img(img_path, target_size = (224, 224)) #Loads an image into PIL format.\n",
        "x = image.img_to_array(img) #Converts a PIL Image instance to a Numpy array.\n",
        "print(x.shape)\n",
        "x = np.expand_dims(x, axis=0) #number of dimensions increased by one\n",
        "print(x.shape)\n",
        "x = preprocess_input(x)\n",
        "print('Input image shape', x.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "(1, 224, 224, 3)\n",
            "Input image shape (1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MUxgAWEOlbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = os.getcwd() #returns current working directory of a process\n",
        "#print(PATH)\n",
        "data_path = PATH + '/data' \n",
        "data_dir_list = os.listdir(data_path) #Return a list containing the names of the entries in the directory given by path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84lYFS94O03I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "fc7fd63d-e829-4a0a-f3bd-0c20f341b591"
      },
      "source": [
        "img_data_list =[]\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "  img_list=os.listdir(data_path+'/'+dataset)\n",
        "  print('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "  for img in img_list:\n",
        "    img_path = data_path + '/' + dataset +'/' + img\n",
        "    img = image.load_img(img_path,target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis =  0)\n",
        "    #x = x/255\n",
        "    #print('Input image shape:', x.shape) same as elephant example above\n",
        "    img_data_list.append(x)\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "#img_data = img_data.astype('float32')\n",
        "print(img_data.shape)\n",
        "img_data = np.rollaxis(img_data,1,0) #roll aixs 1 to axis 0\n",
        "print(img_data.shape)\n",
        "img_data = img_data[0]\n",
        "print(img_data.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the images of dataset-Humans\n",
            "\n",
            "Loaded the images of dataset-dogs\n",
            "\n",
            "Loaded the images of dataset-horses\n",
            "\n",
            "Loaded the images of dataset-cats\n",
            "\n",
            "(808, 1, 224, 224, 3)\n",
            "(1, 808, 224, 224, 3)\n",
            "(808, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YWn1o-ZSgnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1057d778-631c-4ff6-a939-9eea0efc399b"
      },
      "source": [
        "num_classes = 4 # horses, humans, cats, dogs\n",
        "print(img_data.shape[0])\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,), dtype='int64')\n",
        "\n",
        "# in the data.zip file extracted in [2] the images are sorted cats>dogs>horses>humans\n",
        "# with 202 pictures in each category\n",
        "\n",
        "labels[0:202] = 0\n",
        "labels[202:404] = 1\n",
        "labels[404:606] = 2\n",
        "labels[606:808] = 3\n",
        "\n",
        "names = ['cats', 'dogs', 'horses', 'humans']\n",
        "\n",
        "#convert to one_hot\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "# shuffle\n",
        "x,y = shuffle(img_data, Y, random_state=2) #shuffle sparse dataset in a consistent way - similar to resampling \n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU7bzLI_YWuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "outputId": "67f6223a-e21c-4199-bb0d-56bcaf218ff3"
      },
      "source": [
        "image_input = Input(shape=(224,224,3)) # shape of single image\n",
        "\n",
        "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet') # include the 3 fully-connected layers at the top of the network with pre-learned weights\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "552591360/553467096 [============================>.] - ETA: 0s_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ZsWJ2yZp2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "9f4aedbc-55ae-4de5-f385-bacdd9685dc3"
      },
      "source": [
        "last_layer = model.get_layer('fc2').output # retrieves the output of fc2\n",
        "out = Dense(num_classes, activation= 'softmax', name='output')(last_layer) # replace 'predictions' with 'output'\n",
        "custom_vgg_model = Model(image_input, out) \n",
        "custom_vgg_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 134,276,932\n",
            "Trainable params: 134,276,932\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrJUNIkkciLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "9ba9760b-1946-47de-eb77-420967d3ff23"
      },
      "source": [
        "for layer in custom_vgg_model.layers[:-1]:   #excluding last layer\n",
        "   layer.trainable = False\n",
        "\n",
        "custom_vgg_model.layers[3].trainable #makes 3rd layer trainable although it may be left untrainable\n",
        "custom_vgg_model.summary()\n",
        "\n",
        "custom_vgg_model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 134,276,932\n",
            "Trainable params: 16,388\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TUFOAV4fhNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "4f5fec3f-34c7-42b5-85f9-41fe1de04907"
      },
      "source": [
        "t=time.time()\n",
        "\n",
        "hist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epochs=2, verbose=1, validation_data=(X_test, y_test))\n",
        "print('Training time: %s' % (t - time.time()))\n",
        "(loss, accuracy) = custom_vgg_model.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 646 samples, validate on 162 samples\n",
            "Epoch 1/2\n",
            "646/646 [==============================] - 1411s - loss: 0.6139 - acc: 0.8421 - val_loss: 0.2776 - val_acc: 0.9074\n",
            "Epoch 2/2\n",
            "160/646 [======>.......................] - ETA: 846s - loss: 0.0927 - acc: 0.9563"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX6x4KV7gjIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# visualizing losses and accuracy\n",
        "\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "xc=range(2)\n",
        "\n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'],loc=4)\n",
        "\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "\n",
        "plt.style.use(['classic'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}